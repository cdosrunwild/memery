{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memery\n",
    "\n",
    "> Use human language to search your image folders!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## What is memery?\n",
    "\n",
    "![meme about having too many memes](images/E2GoeMyWEAAkcLz.jpeg)\n",
    "\n",
    "The problem: you have a huge folder of images. Memes, screenshots, datasets, product photos, inspo albums, anything. You know that somewhere in that folder is the exact image you want, but you can't remember the filename or what day you saved it. There's nothing you can do but scroll through the folder, skimming hundreds of thumbnails, hoping you don't accidentally miss it, and that you'll recognize it when you do see it. \n",
    "\n",
    "Humans do this amazingly well. But even with computers, local image search is still a manual effort - you're still sorting through folders of images, like an archivist of old.\n",
    "\n",
    "**Now there's Memery**.\n",
    "\n",
    "The `memery` package provides natural language search over local images. You can use it to search for things like \"a line drawing of a woman facing to the left\" and get _reasonably good results!_ \n",
    "\n",
    "You can do this over thousands of images (it's not optimized for performance yet, but search times scale well under O(n)). \n",
    "\n",
    "You can view the images in a browser GUI, or pipe them through command line tools. \n",
    "\n",
    "You can use `memery` or its modules in Jupyter notebooks, including GUI functions! \n",
    "\n",
    "Under the hood, `memery` makes use of **CLIP**, the [Contrastive Language-Image Pretraining transformer](https://github.com/openai/CLIP), released by OpenAI in 2021. CLIP trains a vision transformer and a language transformer to find the same latent space for images and their captions. This makes it perfect for the purpose of natural language image search. CLIP is a giant achievement, and `memery` stands on its shoulders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outline:\n",
    "- Usage\n",
    "  - Install locally\n",
    "  - Use GUI\n",
    "  - Use CLI\n",
    "  - Use in Jupyter\n",
    "  - Use the library\n",
    "- Development\n",
    "  - Notebook-driven development\n",
    "  - Pull the repo\n",
    "  - Notebook-driven development\n",
    "  - Change the notebooks\n",
    "  - Test the notebooks\n",
    "  - Notebook-driven development\n",
    "  - Tangle the source code\n",
    "  - Weave the documentation\n",
    "  - Commit your changes\n",
    "- Contributing\n",
    "  - Who works on this project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "With Python 3.6 or greater:\n",
    "\n",
    "```\n",
    "pip install memery\n",
    "pip install git+https://github.com/openai/CLIP.git\n",
    "```\n",
    "\n",
    "Currently memery defaults to GPU installation. This will \n",
    "probably be switched in a future version. \n",
    "\n",
    "For now, if you want to run CPU-only, run the following command after installing memery:\n",
    "\n",
    "`pip install torch==1.7.1+cpu torchvision==0.8.2+cpu torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html`\n",
    "\n",
    "Someday memery will be packaged in an easy to use format, but since this is a Python project it is hard to predict when that day will be.\n",
    "\n",
    "If you want to help develop memery, you'll need to clone the repo. See below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage\n",
    "\n",
    "What's your use case? \n",
    "\n",
    "**I have images and want to search them with a GUI app**\n",
    "   \n",
    "   ↳  Use the Browser GUI\n",
    "   \n",
    "**i have a program/workflow and want to use image search as one part of it**\n",
    "  \n",
    "   ↳ Use in Jupyter\n",
    "   \n",
    "   ↳ Use as a Python module\n",
    "   \n",
    "   ↳ Use from command line or shell scripts\n",
    "   \n",
    "**i want to improve on and/or contribute to memery development**\n",
    " \n",
    "   ↳ Start by cloning the repo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use GUI\n",
    "\n",
    "Currently memery has a rough browser-based GUI. To launch it, run the following in a command line: \n",
    "\n",
    "```memery serve```\n",
    "\n",
    "or set up a desktop shortcut that points to the above command.\n",
    "\n",
    "Memery will open in a browser window. The interface is pretty straightforward, but it has some quirks.\n",
    "\n",
    "![screenshot of memery GUI displaying wholesome memes](./images/streamlit-screenshot.png)\n",
    "\n",
    "The sidebar on the left controls the location and query for the search. The \"Directory\" box requires a full directory path; unfortunately, Streamlit does not yet have a folder-picker component. The path is relative to your current working directory when you run `memery serve`.\n",
    "\n",
    "The search will run once you enter a text or image query. If you enter both text and image queries, memery will search for the combination.\n",
    "\n",
    "Beneath these widgets is the output area for temporary messages displayed with each search. Mostly this can be ignored.\n",
    "\n",
    "The right hand panel displays the images and associated options. Major errors will appear here as giant stack traces; sometimes, changing variables in the other widgets will fix these errors live. If you get a large error here it's helpful to take a screenshot and share it with us in Github Issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use in Jupyter\n",
    "\n",
    "If you're in a Jupyter environment, you can summon an ipywidgets GUI directly into an output cell like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memery.gui import appPage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7170f06efa2849d586bc9b2d811b84bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AppLayout(children=(Box(children=(Text(value='images/', layout=Layout(max_width='80%'), placeholder='path/to/i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<memery.gui.appPage at 0x7f829c87d290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "app = appPage()\n",
    "display(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![screenshot of memery Jupyter GUI displaying wholesome memes](./images/jupyter-screenshot.png)\n",
    "\n",
    "Unfortunately the widgets won't display without an active runtime, so the above is a screenshot. In a Jupyter environment, the GUI works just like the browser-based GUI. \n",
    "\n",
    "Opening new appPage instances in separate cells can be helpful for exploring a dataset, but it can also cause memory overruns. For this reason the Jupyter interface is tabbed and each search will appear in a new tab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use CLI\n",
    "\n",
    "The memery command line is currently very rudimentary. So far you can use `memery` on any folder and it will search for images recursively, returning a list object to stdout. \n",
    "\n",
    "Pass the --n flag to control how many images are returned (default 10).\n",
    "\n",
    "`memery recall PATH/TO/IMAGE/FOLDER 'query' --n 20`\n",
    "\n",
    "I'm not clear yet on what behavior command-line users will expect from it. In the future we may want to make it non-recursive by default, and map the behavior more closely to POSIX standards. I would love feedback or help on this.\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use as a library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function currently called `query_flow` accepts a folder name and a query and returns a ranked list of image files. This is also recursive by default, and prints too much information into stdout. And it calls index_flow every time, which can be annoying if you have corrupted files in the directory, as it will need to rebuild the tree-index each time despite the files not changing. This will be solved in a future release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memery.core import query_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "89it [00:00, 44503.23it/s]\n",
      "89it [00:00, 37660.72it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting timer\n",
      "Checking files\n",
      "Indexing\n",
      "Skipping bad file: images/memes/corrupted-file.jpeg\n",
      "due to <class 'PIL.UnidentifiedImageError'>\n",
      "Skipping bad file: images/memes/.ipynb_checkpoints/corrupted-file-checkpoint.jpeg\n",
      "due to <class 'PIL.UnidentifiedImageError'>\n",
      "Loaded 82 encodings\n",
      "Encoding 0 new images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building treemap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 82 encodings\n",
      "Converting query\n",
      "Searching 82 images\n",
      "Done in 0.5853581428527832 seconds\n",
      "['images/memes/Wholesome-Meme-68.jpg', 'images/memes/Wholesome-Meme-74.jpg', 'images/memes/Wholesome-Meme-88.jpg', 'images/memes/Wholesome-Meme-78.jpg', 'images/memes/Wholesome-Meme-23.jpg']\n"
     ]
    }
   ],
   "source": [
    "ranked = query_flow('./images', 'dad joke')\n",
    "\n",
    "print(ranked[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the first result from that list:\n",
    "\n",
    "![](images/memes/Wholesome-Meme-68.jpg)\n",
    "\n",
    "\n",
    "So that's how to use memery. Let's look at how you can help make it better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development\n",
    "\n",
    "Memery is a different beast than most pieces of code you've seen. It's a *literate program*: a program written for human beings to read.\n",
    "\n",
    "Nothing in this code is particularly special. The algorithms, data structures, and pipeline are either bog-standard or even subpar. The model was developed by OpenAI, and the tree indexer by Spotify. All I did was glue a bunch of disparate things together. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook-driven development\n",
    "\n",
    "The thing that makes this program interesting is that it was developed **in Jupyter notebooks**. Each component has its code and documentation in the same place, a `.ipynb` notebook.\n",
    "\n",
    "This is possible thanks to a new-ish project called `nbdev`. It provides literate programming functionality for notebooks. Specifically, it allows the programmer to automatically weave code and tangle documentation from the content of the notebooks!\n",
    "\n",
    "This means that relevant docs, code and tests for that code all live in the same location. And ideally, that place is a notebook *written for humans*. I'm still getting the hang of this, but it means explaining *why* something works, rather than simply how to do it.\n",
    "\n",
    "So that's the *why* of notebook-driven development. Let's look at *how* that works in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull the repo\n",
    "\n",
    "Clone this repository from Github:\n",
    "\n",
    "`git clone https://github.com/deepfates/memery.git`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies and memery\n",
    "Enter the `memery` folder and install requirements:\n",
    "\n",
    "```\n",
    "cd memery\n",
    "pip install requirements.txt\n",
    "```\n",
    "\n",
    "We also have to download the CLIP model directly from their git repo, as they decline to upload it to PyPi:\n",
    "\n",
    "`pip install git+https://github.com/openai/CLIP.git`\n",
    "\n",
    "And finally install your local, editable copy of memery with \n",
    "\n",
    "`pip install -e .`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook-driven development\n",
    "\n",
    "Within the main memery folder there is a subfolder `memery/memery`. This contains `.py` files, which are the source code for the repo. You might be tempted to edit these Python files directly, but you must hesitate.\n",
    "\n",
    "Remember: we are doing notebook-driven development. The Python files in that folder are auto-generated from the `.ipynb` files in this folder. If you edit them directly, the notebooks could overwrite your code in a future build. There are ways to backport code from the `.py` files to the notebooks, but it's not recommended.\n",
    "\n",
    "The reason we write the code in notebooks is to keep documentation and tests right next to their code. This single source of truth will percolate to the docs, code packages and testing framework. \n",
    "\n",
    " :warning: Always edit the notebook files, not the .py files! :warning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the notebooks\n",
    "\n",
    "This is the part you came here for. Change the code in the notebooks as you need. \n",
    "\n",
    "Change the **documentation** as well, to match your new code. Code should be documented as closely to the cell where it is used as possible. The more general design should be at the top of the notebook, and implementation-specific details further down.\n",
    "\n",
    "Each notebook should also contain **tests** for the code it defines. These can be simple assert statements which return True.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the notebooks\n",
    "\n",
    "The following command will run each notebook in the main folder and report if any cells return False or raise errors. We pause for a couple seconds between starting each notebook, to avoid collisions accessing the GPU.\n",
    "\n",
    "`nbdev_test_nbs --pause 2`\n",
    "\n",
    "Always run tests before committing your changes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook-driven development\n",
    "\n",
    "As an interpreted language, Python doesn't usually have a \"compile\" step. But as a literate program, Memery is written for humans first and computers second. To get a clean Python module, free of documentation and tests, we **tangle** the source code into the `/memery` directory, then **weave** the documentation.\n",
    "\n",
    "Any code with the `#export` tag at the beginning of its cell will be tangled into the appropriate .py file. Any code cell with `#hide` will be hidden from the docs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tangle the source code\n",
    "\n",
    "To tangle code into `/memery`, use the following in a command line:\n",
    "\n",
    "`nbdev_build_lib`\n",
    "\n",
    "I often use `nbdev_build_lib && pip install -e` (although I'm no longer sure if it's necessary to reinstall an editable module)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weave the documentation\n",
    "\n",
    "To generate the documentation website, use `nbdev_build_docs`. Or, get a live preview using `make docs_serve`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commit your changes\n",
    "\n",
    "Before committing, clean useless metadata from your notebooks with `nbdev_clean_nbs`. Or, install the nbdev pre-commit hooks to do this automatically with `nbdev_install_git_hooks`.\n",
    "\n",
    "Then commit your changes to the repo and push! Make sure to include the `/docs` and `/memery` folders, and any notebooks you changed when you commit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributing\n",
    "\n",
    "Memery is open source and you can contribute. See [CONTRIBUTING.md]('/CONTRIBUTING.md') for guidelines on how you can help.\n",
    "\n",
    "### Who works on this project\n",
    "\n",
    "Memery was first written by Max Anton Brewer aka @deepfates in the summer of 2021. Some commits are listed from @robotface-io but that was just me using the wrong account when I first started. \n",
    "\n",
    "I wrote this to solve my own needs and learn notebook-based development. I hope it helps other people too. If you can help me make it better, please do. I welcome any contribution, guidance or criticism.\n",
    "\n",
    "**The ideal way to get support is to open an issue on Github**. However, the *fastest* way to get a response from me is probably to [direct message me on twitter](twitter.com/deepfates). This is my first attempt to coordinate an open-source project, bear with me.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
